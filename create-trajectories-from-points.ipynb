{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kappazunder bildstandorte vom stadt wien wfs server laden und als points.gpkg ablegen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28443,
     "status": "ok",
     "timestamp": 1762696699231,
     "user": {
      "displayName": "Elias Gander",
      "userId": "00320090336903503101"
     },
     "user_tz": -60
    },
    "id": "9wivA_obPx1Z",
    "outputId": "2c500fbd-c1a5-4435-a4bf-ed6c29eb8ff4"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "points = gpd.read_file(\"points.gpkg\", layer=\"kappazunder_image_punkte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B-I7_ueOP7f7"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def to_snake_case(s):\n",
    "    s = s.strip()               \n",
    "    s = s.lower()            \n",
    "    s = re.sub(r'[ -]+', '_', s)\n",
    "    s = re.sub(r'[^\\w-]', '', s)\n",
    "    return s\n",
    "\n",
    "points.columns = [to_snake_case(col) for col in points.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timestamps der datenpunkte haben nur sekundenauflösung.  \n",
    "für streng monoton steigende timestamps aufeinanderfolgende datenpunkte mit gleichen timestamps in 100ms schritten separieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "35x0kgGeP9XW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "points = points.sort_values(['trajectoryid', 'epoch', 'objectid']).reset_index(drop=True)\n",
    "\n",
    "# Add milliseconds offset within each (trajectoryid, epoch) group\n",
    "points['ms_offset'] = points.groupby(['trajectoryid', 'epoch']).cumcount() * 100\n",
    "\n",
    "# Apply offset as timedelta (1 ms per duplicate)\n",
    "points['epoch'] = points['epoch'] + pd.to_timedelta(points['ms_offset'], unit='ms')\n",
    "\n",
    "# Drop helper column\n",
    "points = points.drop(columns='ms_offset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bildstandorte sind in epsg:31256, später brauchen wir zusätzlich wsg84\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q69EDA6KP--N"
   },
   "outputs": [],
   "source": [
    "points_wsg84 = points.to_crs(epsg=4326)\n",
    "points[\"lat\"] = points_wsg84.geometry.y\n",
    "points[\"lon\"] = points_wsg84.geometry.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trajectoryid als string interpretieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1762696709444,
     "user": {
      "displayName": "Elias Gander",
      "userId": "00320090336903503101"
     },
     "user_tz": -60
    },
    "id": "1795wMyPQAXa",
    "outputId": "82a852a0-2b9a-4495-e37f-08fa993f5fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New trajectoryid dtype: object\n",
      "\n",
      "Sample of trajectoryid values:\n",
      "0    15419\n",
      "1    15419\n",
      "2    15419\n",
      "3    15419\n",
      "4    15419\n",
      "Name: trajectoryid, dtype: object\n"
     ]
    }
   ],
   "source": [
    "points['trajectoryid'] = points['trajectoryid'].astype(str).str.replace('.0', '')\n",
    "print(\"New trajectoryid dtype:\", points['trajectoryid'].dtype)\n",
    "print(\"\\nSample of trajectoryid values:\")\n",
    "print(points['trajectoryid'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "der geodatenviewer erlaubt maximal 80gb große downloads.\n",
    "\n",
    "bei guten 20mb pro datenpunkt macht das etwa 3500 datenpunkten pro download.\n",
    "\n",
    "die günstige vm bei hetzner hat nur 40gb ssd. außerdem muss das heruntergeladene archiv entpackt werden.\n",
    "ein archiv muss also etwas unter 20gb haben. damit sind wir bei unter 1000 datenpunkten pro download.\n",
    "\n",
    "die eine trajektorie umfassenden polygone werden zu einem gewissen grad auch trajektorie-fremde datenpunkte umschließen was den download vergrößert. deswegen pro download paket maximal 750 datenpunkte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1762696709652,
     "user": {
      "displayName": "Elias Gander",
      "userId": "00320090336903503101"
     },
     "user_tz": -60
    },
    "id": "k123P_aXQBnE",
    "outputId": "29bc1d1d-c6f1-45bc-97cf-99cc7d866962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 Trajektorien\n",
      "Datenpunkte pro Trajektorie:\n",
      "trajectoryid\n",
      "15728    21114\n",
      "16442    20582\n",
      "15433    20311\n",
      "15419    20106\n",
      "16653    19793\n",
      "         ...  \n",
      "17720       56\n",
      "16101       40\n",
      "16471       28\n",
      "15432        3\n",
      "17096        2\n",
      "Name: count, Length: 175, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{points['trajectoryid'].nunique()} Trajektorien\")\n",
    "print(\"Datenpunkte pro Trajektorie:\")\n",
    "print(points[\"trajectoryid\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "die trajektorien müssen also aufgeteilt werden.\n",
    "\n",
    "die datenpunkte jeder trajektorie chronologisch sortieren über die objectid und in untertrajektorien mit maximal 750 datenpunkten aufteilen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2570,
     "status": "ok",
     "timestamp": 1762696712225,
     "user": {
      "displayName": "Elias Gander",
      "userId": "00320090336903503101"
     },
     "user_tz": -60
    },
    "id": "_vEJx_MCQC8c",
    "outputId": "56cd9ddc-4a94-4137-8b49-bdbfabe1196c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 183.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original trajectories: 175\n",
      "Split trajectories: 1917\n",
      "Counts per split:\n",
      "trajectoryid\n",
      "17562_1    750\n",
      "21441_3    750\n",
      "16876_2    750\n",
      "16876_1    750\n",
      "16876_0    750\n",
      "          ... \n",
      "17720       56\n",
      "16101       40\n",
      "16471       28\n",
      "15432        3\n",
      "17096        2\n",
      "Name: count, Length: 1917, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "\n",
    "original_trajectories_count = points['trajectoryid'].nunique()\n",
    "\n",
    "records = []\n",
    "for traj_id, group in tqdm(points.groupby('trajectoryid')):\n",
    "    group_sorted = group.sort_values('objectid')\n",
    "    n = len(group_sorted)\n",
    "    if n == 0:\n",
    "        continue\n",
    "    no_of_splits = int(ceil(n / 750))\n",
    "    base = n // no_of_splits\n",
    "    remainder = n % no_of_splits\n",
    "    sizes = [base + 1] * remainder + [base] * (no_of_splits - remainder)\n",
    "    i = 0\n",
    "    for split_i, size in enumerate(sizes):\n",
    "        end = i + size\n",
    "        part = group_sorted.iloc[i:end].copy()\n",
    "        part['trajectoryid'] = f\"{traj_id}_{split_i}\" if len(sizes) > 1 else traj_id\n",
    "        records.append(part)\n",
    "        i = end\n",
    "\n",
    "points_split = gpd.GeoDataFrame(pd.concat(records, ignore_index=True), crs=points.crs)\n",
    "\n",
    "print(f\"Original trajectories: {original_trajectories_count}\")\n",
    "print(f\"Split trajectories: {points_split['trajectoryid'].nunique()}\")\n",
    "print(\"Counts per split:\")\n",
    "print(points_split['trajectoryid'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "der geodatenviewer benötigt einen die gewünschten datenpunkte umfassenden polygon.\n",
    "\n",
    "dazu die datenpunkte jeder trajektorie chronologisch zu einem linestring verbinden und diesen auf 1 meter dicke buffern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28728,
     "status": "ok",
     "timestamp": 1762696741024,
     "user": {
      "displayName": "Elias Gander",
      "userId": "00320090336903503101"
     },
     "user_tz": -60
    },
    "id": "6key75aUQEnK",
    "outputId": "608b9fcc-5928-4cc2-c073-d2d192b77a3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1917/1917 [00:06<00:00, 292.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectories (lines): 1917\n",
      "Buffered geometries: 1917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  trajectoryid                                           geometry\n",
       " 0      15419_0  LINESTRING (-601.117 337164.375, -639.231 3371...\n",
       " 1      15419_1  LINESTRING (-2268.27 337022.539, -2274.858 337...\n",
       " 2     15419_10  LINESTRING (24.193 337690.697, 22.957 337708.5...\n",
       " 3     15419_11  LINESTRING (293.683 338439.65, 303.067 338424....\n",
       " 4     15419_12  LINESTRING (-150.774 337586.244, -149.835 3375...,\n",
       "   trajectoryid                                           geometry\n",
       " 0      15419_0  POLYGON ((-639.122 337155.512, -674.282 337147...\n",
       " 1      15419_1  POLYGON ((-2490.5 337001.286, -2492.318 337002...\n",
       " 2     15419_10  POLYGON ((18.156 337814.436, 19.032 337800.925...\n",
       " 3     15419_11  POLYGON ((-368.22 338254.55, -367.019 338255.3...\n",
       " 4     15419_12  POLYGON ((-149.341 337577.431, -148.629 337574...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shapely.geometry import LineString\n",
    "\n",
    "records = []\n",
    "for traj_id, group in tqdm(points_split.groupby('trajectoryid')):\n",
    "    group_sorted = group.sort_values('objectid')\n",
    "    geoms = list(group_sorted.geometry)\n",
    "    if len(geoms) == 0:\n",
    "        continue\n",
    "    if len(geoms) == 1:\n",
    "        # single point trajectory -> keep point (buffer will still work)\n",
    "        line_geom = geoms[0]\n",
    "    else:\n",
    "        coords = [(pt.x, pt.y) for pt in geoms]\n",
    "        line_geom = LineString(coords).simplify(0.1)\n",
    "    records.append({'trajectoryid': traj_id, 'geometry': line_geom})\n",
    "\n",
    "# GeoDataFrame of lines (or single-point geometries for 1-point trajectories)\n",
    "trajectory_lines = gpd.GeoDataFrame(records, crs=points_split.crs)\n",
    "\n",
    "# Buffer by 0.5 meter (CRS is EPSG:31256 so units are meters)\n",
    "trajectories = trajectory_lines.copy()\n",
    "trajectories['geometry'] = trajectories.geometry.buffer(0.5, cap_style=3, join_style=2)\n",
    "\n",
    "print(\"Trajectories (lines):\", len(trajectory_lines))\n",
    "print(\"Buffered geometries:\", len(trajectories))\n",
    "\n",
    "# Optionally inspect first rows\n",
    "trajectory_lines.head(), trajectories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aufbereitete datenpunkte und trajektorie-polygone abspeichern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qp6EN1B3QHWn"
   },
   "outputs": [],
   "source": [
    "points.to_file(\n",
    "    \"points.gpkg\", driver=\"GPKG\", layer=\"kappazunder_image_punkte\", index=False\n",
    ")\n",
    "trajectories.to_file(\"trajectories.gpkg\", driver=\"GPKG\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPb6h0IXPqYt6cZLuYQ3ucJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
